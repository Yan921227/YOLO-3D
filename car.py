#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
YOLO-3D åœè»Šæ ¼åµæ¸¬ï¼ˆå®Œæ•´åŠŸèƒ½ç‰ˆï¼‰
  â€¢ æ‰‹å‹•æ¨™å®šå–®æ‡‰ã€åŠƒè»Šæ ¼
  â€¢ é€å¹€æ¨è«–ï¼šYOLOv11 + Depth Anything â†’ 3D BOX
  â€¢ ä¸»ç•«é¢/ä¿¯è¦–åœ–åŒæ­¥é¡¯ç¤ºã€åˆ¤æ–·ä½”ç”¨
  â€¢ åŸ·è¡Œçµæœå¯è¼¸å‡º MP4
"""
import argparse
import cv2
import numpy as np
from shapely.geometry import Polygon

# -------- 2D / Depth / 3D å·¥å…· --------
from detection_model import ObjectDetector
from depth_model import DepthEstimator
from bbox3d_utils import BBox3DEstimator, BirdEyeView

# -------- CLI åƒæ•¸ --------
parser = argparse.ArgumentParser()
parser.add_argument('--video',      type=str, default='C:\\Users\\User\\Desktop\\car.mp4')
parser.add_argument('--out_video',  type=str, default='result.mp4',
                    help='ç•™ç©ºå­—ä¸² ("") å‰‡ä¸è¼¸å‡ºå½±ç‰‡')
parser.add_argument('--yolo_size',  type=str, default='small',
                    choices=['nano', 'small', 'medium', 'large', 'extra'])
parser.add_argument('--depth_size', type=str, default='small',
                    choices=['small', 'base', 'large'])
parser.add_argument('--device',     type=str, default='cuda:0')
parser.add_argument('--conf',       type=float, default=0.4)
parser.add_argument('--debug',      action='store_true', help='é¡¯ç¤ºé™¤éŒ¯æ–‡å­—')
args = parser.parse_args()

# -------- é–‹å•Ÿå½±ç‰‡ & è®€å–é¦–å½±æ ¼ --------
cap = cv2.VideoCapture(args.video)
ret, frame = cap.read()
if not ret:
    raise IOError(f'ç„¡æ³•é–‹å•Ÿå½±ç‰‡ {args.video}')

H, H_inv          = None, None
parking_polys     = []   # Shapely Polygon (åˆ¤æ–·)
parking_draw_pts  = []   # np.int32 (N,1,2) (ç¹ªåœ–)

# ========== 1. æ‰‹å‹•æ¨™å®šå–®æ‡‰ (é»åœ°é¢ 4 é») ==========
src_points = []
def click_homography(evt, x, y, *_):
    if evt == cv2.EVENT_LBUTTONDOWN and len(src_points) < 4:
        src_points.append([x, y])
        cv2.circle(tmp, (x, y), 5, (0, 0, 255), -1)
        cv2.imshow('Select Plane', tmp)

tmp = frame.copy()
cv2.imshow('Select Plane', tmp)
cv2.setMouseCallback('Select Plane', click_homography)
print('è«‹é»æ“Šåœ°é¢çŸ©å½¢ 4 è§’ (é †åºä¸é™)â€¦')
while len(src_points) < 4:
    cv2.waitKey(1)
cv2.destroyWindow('Select Plane')

w_bev, h_bev = 800, 600
dst_points = np.float32([[0, 0], [w_bev, 0], [w_bev, h_bev], [0, h_bev]])
H, _  = cv2.findHomography(np.float32(src_points), dst_points)
H_inv = np.linalg.inv(H)

# ========== 2. æ‰‹å‹•ç¹ªè£½åœè»Šæ ¼ (ä¿¯è¦–åœ–) ==========
warp        = cv2.warpPerspective(frame, H, (w_bev, h_bev))
warp_show   = warp.copy()
frame_preview = frame.copy()
current_pts  = []

def click_slot(evt, x, y, *_):
    if evt != cv2.EVENT_LBUTTONDOWN:
        return
    current_pts.append((x, y))
    cv2.circle(warp_show, (x, y), 4, (255, 0, 0), -1)

    if len(current_pts) == 4:
        # åœ¨ BEV ç•«ç·š
        cv2.polylines(warp_show,
                      [np.array(current_pts, dtype=np.int32).reshape(-1, 1, 2)],
                      True, (0, 255, 0), 2)

        # è½‰å›åŸå½±åƒåº§æ¨™
        pts = np.float32(current_pts).reshape(-1, 1, 2)
        inv = cv2.perspectiveTransform(pts, H_inv).reshape(-1, 2)

        inv[:, 0] = np.clip(inv[:, 0], 0, frame.shape[1] - 1)
        inv[:, 1] = np.clip(inv[:, 1], 0, frame.shape[0] - 1)

        poly  = Polygon(inv)
        parking_polys.append(poly)
        draw  = np.array(inv, dtype=np.int32).reshape(-1, 1, 2)
        parking_draw_pts.append(draw)

        # ç«‹å³åœ¨åŸåœ–é è¦½
        cv2.polylines(frame_preview, [draw], True, (0, 0, 255), 3)
        cv2.imshow('Frame Preview', frame_preview)
        print(f"Saved slot #{len(parking_polys)}")

        current_pts.clear()
    cv2.imshow('Warp', warp_show)

cv2.imshow('Warp', warp_show)
cv2.setMouseCallback('Warp', click_slot)
print('åœ¨ä¿¯è¦–åœ–ä¾åºé»å››å€‹è§’å½¢æˆä¸€æ ¼ï¼ŒESC çµæŸâ€¦')
while True:
    if cv2.waitKey(1) == 27:
        break
cv2.destroyWindow('Warp')
cv2.destroyWindow('Frame Preview')

if len(parking_polys) == 0:
    print('âš ï¸ æ²’æœ‰å®šç¾©ä»»ä½•è»Šæ ¼ï¼Œç¨‹å¼å°‡åªé¡¯ç¤º 3D åµæ¸¬çµæœã€‚')

# ========== 3. å½±ç‰‡è¼¸å‡ºè¨­å®š ==========
writer = None
if args.out_video.strip():
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')        # éœ€å®‰è£å°æ‡‰ codec
    fps    = cap.get(cv2.CAP_PROP_FPS) or 30
    h_out, w_out = frame.shape[:2]
    writer = cv2.VideoWriter(args.out_video, fourcc, fps, (w_out, h_out))
    print(f'ğŸ”´  å°‡è¼¸å‡ºçµæœè‡³ {args.out_video} (size={w_out}Ã—{h_out}, fps={fps:.1f})')
else:
    print('âšª  ä¸è¼¸å‡ºå½±ç‰‡ (--out_video="")')

# ========== 4. è¼‰å…¥æ¨¡å‹ ==========
print('è¼‰å…¥ 2Dã€æ·±åº¦èˆ‡ 3D æ¨¡å‹â€¦')
detector  = ObjectDetector(model_size=args.yolo_size, conf_thres=args.conf, device=args.device)
depthnet  = DepthEstimator(model_size=args.depth_size,    device=args.device)
estimator = BBox3DEstimator()
bev       = BirdEyeView(size=(w_bev, h_bev), scale=50, camera_height=1.2)

# ========== 5. é€å¹€æ¨è«– ==========
cap.set(cv2.CAP_PROP_POS_FRAMES, 0)
while True:
    ret, frame = cap.read()
    if not ret:
        break

    annotated, dets = detector.detect(frame, track=True)
    depth_map = depthnet.estimate_depth(frame)
    bev.reset()

    parking_occupied = [False] * len(parking_polys)

    # ---- è™•ç†å„åµæ¸¬ ----
    for bbox2d, score, cls_id, obj_id in dets:
        if cls_id != 2:     # åªçœ‹ car
            continue
        x1, y1, x2, y2 = map(int, bbox2d)
        cx, cy         = (x1 + x2) // 2, y2
        depth_val      = float(depth_map[cy, cx])
        box3d = estimator.estimate_3d_box(
                    [x1, y1, x2, y2],
                    depth_val,
                    detector.get_class_names()[cls_id],
                    object_id=obj_id)
        annotated = estimator.draw_box_3d(annotated, box3d)
        bev.draw_box(box3d)

        # ---- åˆ¤æ–·æ˜¯å¦é€²å…¥åœè»Šæ ¼ ----
        for idx, pts in enumerate(parking_draw_pts):
            if cv2.pointPolygonTest(pts, (cx, cy), False) >= 0:
                parking_occupied[idx] = True

    # ---- ç¹ªè£½åœè»Šæ ¼ (ç´…/ç¶ ) ----
    for idx, pts in enumerate(parking_draw_pts):
        occ   = parking_occupied[idx]
        color = (0, 255, 0) if occ else (0, 0, 255)     # ç¶ =ä½”ç”¨ã€ç´…=ç©º
        cv2.polylines(annotated, [pts], True, color, 4)
        label = f'Slot {idx+1} OCCUPIED' if occ else f'Slot {idx+1} EMPTY'
        cv2.putText(annotated, label, tuple(pts[0][0]-np.array([0, 5])),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.55, color, 2)

    # ---- Debug æ–‡å­— (å¯é¸) ----
    if args.debug:
        y_dbg = 25
        for idx, occ in enumerate(parking_occupied):
            txt = f'[dbg] slot{idx+1}: {"in" if occ else "out"}'
            cv2.putText(annotated, txt, (5, y_dbg),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
            y_dbg += 18

    # ---- å½±ç‰‡å¯«æª” ----
    if writer is not None:
        writer.write(annotated)

    # ---- é¡¯ç¤º ----
    cv2.imshow('Result-3D', annotated)
    cv2.imshow('BirdEye', bev.get_image())
    if cv2.waitKey(1) == 27:      # ESC çµæŸ
        break

# ========== 6. æ”¶å°¾ ==========
cap.release()
if writer is not None:
    writer.release()
cv2.destroyAllWindows()
print('âœ…  å½±ç‰‡è™•ç†å®Œæˆã€‚')
